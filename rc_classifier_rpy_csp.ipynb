{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8f39ff4d",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "687bdf95",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from mne.decoding import CSP\n",
    "import scipy.io\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score, f1_score, cohen_kappa_score, confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.linear_model import RidgeClassifier\n",
    "from sklearn.metrics import cohen_kappa_score\n",
    "from tqdm import tqdm\n",
    "from sklearn.linear_model import RidgeClassifierCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from pyrcn.echo_state_network import ESNClassifier\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader, TensorDataset\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from tqdm import tqdm\n",
    "import cupy as cp\n",
    "import reservoirpy as rpy\n",
    "from reservoirpy.nodes import Reservoir\n",
    "from reservoirpy.nodes import Ridge\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "import pandas as pd\n",
    "import itertools\n",
    "import plotly.express as px\n",
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "394114c1",
   "metadata": {},
   "source": [
    "## Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eff740a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "subject_id = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e88ac83",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a270150",
   "metadata": {},
   "outputs": [],
   "source": [
    "npz_filename_T = f'./data/train/A0{subject_id}T.npz'\n",
    "npz_filename_E = f'./data/eval/A0{subject_id}E.npz'\n",
    "\n",
    "data_T = np.load(npz_filename_T)\n",
    "data_E = np.load(npz_filename_E)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0d4e9f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = data_T['X']\n",
    "\n",
    "# y_train = np.asarray([np.asarray([item-6 for i in range(X_train.shape[1])]) for item in data_T['y']])\n",
    "y_train = data_T['y'] - 6\n",
    "\n",
    "X_eval = data_E['X']\n",
    "y_true = data_E['y_true']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "414d7e49",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape, y_train.shape, np.max(X_train), np.min(X_train), np.mean(X_train), np.std(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e68239f",
   "metadata": {},
   "source": [
    "## One-Hot encode labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cba1b08",
   "metadata": {},
   "outputs": [],
   "source": [
    "lb = LabelBinarizer()\n",
    "\n",
    "y_train_onehot = lb.fit_transform(y_train)\n",
    "y_true_onehot = lb.transform(y_true)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab445594",
   "metadata": {},
   "source": [
    "## CSP Transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c8cc5c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "csp = CSP(n_components=4, reg=None, log=True, norm_trace=False)\n",
    "\n",
    "csp = csp.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a89f611",
   "metadata": {},
   "outputs": [],
   "source": [
    "csp.filters_.shape, X_train[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04daa95b",
   "metadata": {},
   "outputs": [],
   "source": [
    "[sample.T.shape for sample in X_train][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f898e788",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_csp = np.asarray([csp.transform(sample.T) for sample in X_train])\n",
    "X_eval_csp = np.asarray([csp.transform(sample.T) for sample in X_eval])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83af4361",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape, X_train_csp.shape, X_eval_csp.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81ed916e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_csp.shape, y_train.shape, np.max(X_train_csp), np.min(X_train_csp), np.mean(X_train_csp), np.std(X_train_csp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c19e10e2",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d6c4a796",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20d2f549",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def extract_states(X_data, reservoir, aggregate='mean'):\n",
    "#     states_list = []\n",
    "\n",
    "#     pbar = tqdm(range(len(X_data)))\n",
    "\n",
    "#     for i in pbar:\n",
    "#         data = X_data[i].T\n",
    "\n",
    "#         states = []\n",
    "#         for j in range(data.shape[0]):\n",
    "#             input = data[j].reshape(data[j].shape[0], 1)\n",
    "\n",
    "#             state = reservoir.run(input, workers=-1)\n",
    "\n",
    "#             states.append(state)\n",
    "\n",
    "#         if aggregate == 'final':\n",
    "#             feature = states[-1:, :]\n",
    "#         elif aggregate == 'mean':\n",
    "#             feature = np.mean(states, axis=0, keepdims=True)\n",
    "#         elif aggregate == 'concat':\n",
    "#             # Combine multiple statistics\n",
    "#             feature = np.concatenate([\n",
    "#                 states[-1:, :],\n",
    "#                 np.mean(states, axis=0, keepdims=True),\n",
    "#                 np.std(states, axis=0, keepdims=True)\n",
    "#             ], axis=1)\n",
    "        \n",
    "#         states_list.append(feature)\n",
    "    \n",
    "#     return np.vstack(states_list)\n",
    "\n",
    "def extract_states(X_data, reservoir, aggregate='mean'):\n",
    "    states_list = []\n",
    "\n",
    "    for i in range(len(X_data)):\n",
    "        data = X_data[i]\n",
    "\n",
    "        states = reservoir.run(data, workers=-1)\n",
    "\n",
    "        if aggregate == 'final':\n",
    "            feature = states[-1:, :]\n",
    "        elif aggregate == 'mean':\n",
    "            feature = np.mean(states, axis=0, keepdims=True)\n",
    "        elif aggregate == 'concat':\n",
    "            # Combine multiple statistics\n",
    "            feature = np.concatenate([\n",
    "                states[-1:, :],\n",
    "                np.mean(states, axis=0, keepdims=True),\n",
    "                np.std(states, axis=0, keepdims=True)\n",
    "            ], axis=1)\n",
    "        \n",
    "        states_list.append(feature)\n",
    "    \n",
    "    return np.vstack(states_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "915f6e56",
   "metadata": {},
   "outputs": [],
   "source": [
    "rpy.set_seed(42)\n",
    "\n",
    "# Expected format: (time_steps, channels)\n",
    "reservoir = Reservoir(500, lr=0.1, sr=1.5)\n",
    "\n",
    "readout = Ridge(ridge=1e3)\n",
    "\n",
    "aggregate = 'mean'\n",
    "\n",
    "X_train_csp_states = extract_states(X_train_csp, reservoir, aggregate=aggregate)\n",
    "X_eval_csp_states = extract_states(X_eval_csp, reservoir, aggregate=aggregate)\n",
    "\n",
    "readout.fit(X_train_csp_states, y_train_onehot)\n",
    "\n",
    "y_train_csp_pred = readout.run(X_train_csp_states)\n",
    "y_eval_csp_pred = readout.run(X_eval_csp_states)\n",
    "\n",
    "y_train_pred_class = np.argmax(y_train_csp_pred, axis=1) + 1\n",
    "y_eval_pred_class = np.argmax(y_eval_csp_pred, axis=1) + 1\n",
    "\n",
    "print(f\"Train Accuracy: {accuracy_score(y_train, y_train_pred_class):.4f}\")\n",
    "print(f'Train Kappa: {cohen_kappa_score(y_train, y_train_pred_class)}')\n",
    "print(f\"Eval Accuracy: {accuracy_score(y_true, y_eval_pred_class):.4f}\")\n",
    "print(f'Eval Kappa: {cohen_kappa_score(y_true, y_eval_pred_class)}')\n",
    "\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_true, y_eval_pred_class))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69612281",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "\n",
    "# 1. Your original PCA (unchanged)\n",
    "pca = PCA(n_components=3)\n",
    "X_pca = pca.fit_transform(X_train_csp_states)\n",
    "\n",
    "print(f\"Explained variance ratio: {pca.explained_variance_ratio_}\")\n",
    "print(f\"Total explained variance: {np.sum(pca.explained_variance_ratio_):.3f}\")\n",
    "\n",
    "# 2. Define labels and colors (unchanged)\n",
    "label_names = {1: 'Left Hand', 2: 'Right Hand', 3: 'Feet', 4: 'Tongue'}\n",
    "colors = {1: 'red', 2: 'blue', 3: 'green', 4: 'orange'}\n",
    "\n",
    "# 3. Prepare data for Plotly\n",
    "# Create a DataFrame from your PCA results\n",
    "df_pca = pd.DataFrame(X_pca, columns=['PC1', 'PC2', 'PC3'])\n",
    "df_pca['label'] = y_train\n",
    "\n",
    "# Map numeric labels to meaningful string names (better for legends)\n",
    "df_pca['Class'] = df_pca['label'].map(label_names)\n",
    "\n",
    "# 4. Create the color map for Plotly\n",
    "# This maps the *string name* (e.g., 'Left Hand') to the *color* (e.g., 'red')\n",
    "color_discrete_map = {label_names[key]: colors[key] for key in label_names}\n",
    "\n",
    "# 5. Create the interactive 3D plot\n",
    "fig = px.scatter_3d(\n",
    "    df_pca,\n",
    "    x='PC1',\n",
    "    y='PC2',\n",
    "    z='PC3',\n",
    "    color='Class',  # Column to use for coloring\n",
    "    color_discrete_map=color_discrete_map, # Apply your specific colors\n",
    "    title='Interactive 3D PCA of Reservoir States',\n",
    "    \n",
    "    # Add the variance info to the axis labels\n",
    "    labels={\n",
    "        'PC1': f'PC1 ({pca.explained_variance_ratio_[0]:.2%})',\n",
    "        'PC2': f'PC2 ({pca.explained_variance_ratio_[1]:.2%})',\n",
    "        'PC3': f'PC3 ({pca.explained_variance_ratio_[2]:.2%})'\n",
    "    },\n",
    "    \n",
    "    # Customize what you see on hover\n",
    "    hover_data={'Class': True, 'label': False, 'PC1': ':.3f', 'PC2': ':.3f', 'PC3': ':.3f'}\n",
    ")\n",
    "\n",
    "# Optional: Make markers smaller to match your 's=50' (Plotly's default is a bit larger)\n",
    "fig.update_traces(marker=dict(size=4, opacity=0.7))\n",
    "\n",
    "# 6. Show the figure\n",
    "# In a VSCode Notebook, this will render the fully interactive plot\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e8a085d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_csp_states.shape, y_train_onehot.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73ed9859",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_trial_predictions = []\n",
    "\n",
    "washout_time = 125\n",
    "\n",
    "sample_step = 10\n",
    "\n",
    "# Loop over each trial\n",
    "for trial_data in X_eval_csp:\n",
    "    states = []\n",
    "    trial_predictions = []\n",
    "\n",
    "    for i in range(0, trial_data.shape[0], sample_step):\n",
    "        input = trial_data[i].reshape(1, trial_data[i].shape[0])\n",
    "        \n",
    "        state = reservoir.run(input)\n",
    "\n",
    "        if i >= washout_time:\n",
    "            states.append(state)\n",
    "\n",
    "            mean_state = np.mean(states, axis=0, keepdims=True)\n",
    "\n",
    "            y_pred = readout.run(mean_state).flatten()\n",
    "            y_pred_class = np.argmax(y_pred) + 1\n",
    "\n",
    "\n",
    "            trial_predictions.append(y_pred_class)\n",
    "\n",
    "    all_trial_predictions.append(trial_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "641c5827",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array(all_trial_predictions).T.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77c890a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transpose the prediction matrix so we can score each time point\n",
    "predictions_by_time = np.array(all_trial_predictions).T\n",
    "\n",
    "kappa_scores = []\n",
    "for y_pred_at_time_t in predictions_by_time:\n",
    "    y_pred_mapped = np.array([pred for pred in y_pred_at_time_t])\n",
    "    \n",
    "    kappa = cohen_kappa_score(y_true, y_pred_mapped)\n",
    "    kappa_scores.append(kappa)\n",
    "    acc = accuracy_score(y_true, y_pred_mapped)\n",
    "\n",
    "# --- 5. Find the Final Score ---\n",
    "max_kappa = np.max(kappa_scores)\n",
    "max_acc = np.max(acc)\n",
    "\n",
    "print(f\"Time course of Kappa calculated.\")\n",
    "print(f\"Maximum Kappa value: {max_kappa:.3f}\")\n",
    "print(f\"Maximum Accuracy value: {max_acc:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bea61693",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(kappa_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee600292",
   "metadata": {},
   "source": [
    "## Fine Tune"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2415d42a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(rs, lr, sr, alpha):\n",
    "    reservoir = Reservoir(rs, lr=lr, sr=sr)\n",
    "    readout = Ridge(ridge=alpha)\n",
    "\n",
    "    return reservoir, readout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed71fbe9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Grid Search Progress:   0%|          | 2/405 [01:43<5:47:39, 51.76s/it, rs=500, lr=0.3, sr=0.7, alpha=1]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[67]\u001b[39m\u001b[32m, line 24\u001b[39m\n\u001b[32m     20\u001b[39m pbar.set_postfix({\u001b[33m'\u001b[39m\u001b[33mmax_kappa\u001b[39m\u001b[33m'\u001b[39m: max_kappa, \u001b[33m'\u001b[39m\u001b[33mrs\u001b[39m\u001b[33m'\u001b[39m: rs, \u001b[33m'\u001b[39m\u001b[33mlr\u001b[39m\u001b[33m'\u001b[39m: lr, \u001b[33m'\u001b[39m\u001b[33msr\u001b[39m\u001b[33m'\u001b[39m: sr, \u001b[33m'\u001b[39m\u001b[33malpha\u001b[39m\u001b[33m'\u001b[39m: alpha})\n\u001b[32m     22\u001b[39m reservoir, readout = build_model(rs=rs, lr=lr, sr=sr, alpha=alpha)\n\u001b[32m---> \u001b[39m\u001b[32m24\u001b[39m X_train_csp_states = \u001b[43mextract_states\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train_csp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreservoir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maggregate\u001b[49m\u001b[43m=\u001b[49m\u001b[43maggregate\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     25\u001b[39m X_eval_csp_states = extract_states(X_eval_csp, reservoir, aggregate=aggregate)\n\u001b[32m     27\u001b[39m readout.fit(X_train_csp_states, y_train_onehot)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[54]\u001b[39m\u001b[32m, line 39\u001b[39m, in \u001b[36mextract_states\u001b[39m\u001b[34m(X_data, reservoir, aggregate)\u001b[39m\n\u001b[32m     36\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(X_data)):\n\u001b[32m     37\u001b[39m     data = X_data[i]\n\u001b[32m---> \u001b[39m\u001b[32m39\u001b[39m     states = \u001b[43mreservoir\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mworkers\u001b[49m\u001b[43m=\u001b[49m\u001b[43m-\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     41\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m aggregate == \u001b[33m'\u001b[39m\u001b[33mfinal\u001b[39m\u001b[33m'\u001b[39m:\n\u001b[32m     42\u001b[39m         feature = states[-\u001b[32m1\u001b[39m:, :]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/UCM/experiments/exp#1/.venv/lib/python3.11/site-packages/reservoirpy/node.py:204\u001b[39m, in \u001b[36mNode.run\u001b[39m\u001b[34m(self, x, iters, workers)\u001b[39m\n\u001b[32m    202\u001b[39m         result = \u001b[38;5;28mlist\u001b[39m(result)\n\u001b[32m    203\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m204\u001b[39m     final_state, result = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_run\u001b[49m\u001b[43m(\u001b[49m\u001b[43minitial_state\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    206\u001b[39m \u001b[38;5;28mself\u001b[39m.state = final_state\n\u001b[32m    207\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/UCM/experiments/exp#1/.venv/lib/python3.11/site-packages/reservoirpy/node.py:156\u001b[39m, in \u001b[36mNode._run\u001b[39m\u001b[34m(self, state, x)\u001b[39m\n\u001b[32m    154\u001b[39m output = np.empty((n_timesteps, \u001b[38;5;28mself\u001b[39m.output_dim))\n\u001b[32m    155\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i, x_step \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(x):\n\u001b[32m--> \u001b[39m\u001b[32m156\u001b[39m     current_state = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstate\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcurrent_state\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m=\u001b[49m\u001b[43mx_step\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    157\u001b[39m     output[i] = current_state[\u001b[33m\"\u001b[39m\u001b[33mout\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m    159\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m current_state, output\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/UCM/experiments/exp#1/.venv/lib/python3.11/site-packages/reservoirpy/nodes/reservoir.py:247\u001b[39m, in \u001b[36mReservoir._step\u001b[39m\u001b[34m(self, state, x)\u001b[39m\n\u001b[32m    244\u001b[39m lr = \u001b[38;5;28mself\u001b[39m.lr\n\u001b[32m    245\u001b[39m s = state[\u001b[33m\"\u001b[39m\u001b[33mout\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m--> \u001b[39m\u001b[32m247\u001b[39m next_state = f(\u001b[43mW\u001b[49m\u001b[43m \u001b[49m\u001b[43m@\u001b[49m\u001b[43m \u001b[49m\u001b[43ms\u001b[49m + Win @ x + bias)\n\u001b[32m    248\u001b[39m next_state = (\u001b[32m1\u001b[39m - lr) * s + lr * next_state\n\u001b[32m    250\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m {\u001b[33m\"\u001b[39m\u001b[33mout\u001b[39m\u001b[33m\"\u001b[39m: next_state}\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/UCM/experiments/exp#1/.venv/lib/python3.11/site-packages/scipy/sparse/_base.py:908\u001b[39m, in \u001b[36m_spbase.__matmul__\u001b[39m\u001b[34m(self, other)\u001b[39m\n\u001b[32m    905\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m isscalarlike(other):\n\u001b[32m    906\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mScalar operands are not allowed, \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    907\u001b[39m                      \u001b[33m\"\u001b[39m\u001b[33muse \u001b[39m\u001b[33m'\u001b[39m\u001b[33m*\u001b[39m\u001b[33m'\u001b[39m\u001b[33m instead\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m908\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_matmul_dispatch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mother\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/UCM/experiments/exp#1/.venv/lib/python3.11/site-packages/scipy/sparse/_base.py:793\u001b[39m, in \u001b[36m_spbase._matmul_dispatch\u001b[39m\u001b[34m(self, other)\u001b[39m\n\u001b[32m    790\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m other.\u001b[34m__class__\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m np.ndarray:\n\u001b[32m    791\u001b[39m     \u001b[38;5;66;03m# Fast path for the most common case\u001b[39;00m\n\u001b[32m    792\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m other.shape == (N,):\n\u001b[32m--> \u001b[39m\u001b[32m793\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_matmul_vector\u001b[49m\u001b[43m(\u001b[49m\u001b[43mother\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    794\u001b[39m     \u001b[38;5;28;01melif\u001b[39;00m other.shape == (N, \u001b[32m1\u001b[39m):\n\u001b[32m    795\u001b[39m         result = \u001b[38;5;28mself\u001b[39m._matmul_vector(other.ravel())\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/UCM/experiments/exp#1/.venv/lib/python3.11/site-packages/scipy/sparse/_compressed.py:395\u001b[39m, in \u001b[36m_cs_matrix._matmul_vector\u001b[39m\u001b[34m(self, other)\u001b[39m\n\u001b[32m    393\u001b[39m \u001b[38;5;66;03m# csr_matvec or csc_matvec\u001b[39;00m\n\u001b[32m    394\u001b[39m fn = \u001b[38;5;28mgetattr\u001b[39m(_sparsetools, \u001b[38;5;28mself\u001b[39m.format + \u001b[33m'\u001b[39m\u001b[33m_matvec\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m395\u001b[39m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mM\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mN\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mindptr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mindices\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mother\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresult\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    397\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m result[\u001b[32m0\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.ndim == \u001b[32m1\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m result\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "rs_ls = [500, 1000, 1500]\n",
    "alpha_ls = [1e0, 1e2, 1e4]\n",
    "lr_ls = [0.3, 0.6, 0.9]\n",
    "sr_ls = [0.7, 0.9, 1.2, 1.5, 2.0]\n",
    "aggregate_ls = ['final', 'mean', 'concat']\n",
    "\n",
    "rpy.set_seed(42)\n",
    "\n",
    "results_list = []\n",
    "\n",
    "model_params = list(itertools.product(rs_ls, lr_ls, sr_ls, alpha_ls, aggregate_ls))\n",
    "total_iterations = len(model_params)\n",
    "\n",
    "pbar = tqdm(total=total_iterations, desc=\"Grid Search Progress\")\n",
    "\n",
    "max_kappa = -1\n",
    "\n",
    "for (rs, lr, sr, alpha, aggregate) in model_params:\n",
    "    params = {'max_kappa': max_kappa, 'rs': rs, 'lr': lr, 'sr': sr, 'alpha': alpha}\n",
    "    pbar.set_postfix(params)\n",
    "\n",
    "    reservoir, readout = build_model(rs=rs, lr=lr, sr=sr, alpha=alpha)\n",
    "\n",
    "    X_train_csp_states = extract_states(X_train_csp, reservoir, aggregate=aggregate)\n",
    "    X_eval_csp_states = extract_states(X_eval_csp, reservoir, aggregate=aggregate)\n",
    "\n",
    "    readout.fit(X_train_csp_states, y_train_onehot)\n",
    "\n",
    "    y_train_csp_pred = readout.run(X_train_csp_states)\n",
    "    y_eval_csp_pred = readout.run(X_eval_csp_states)\n",
    "\n",
    "    y_train_pred_class = np.argmax(y_train_csp_pred, axis=1) + 1\n",
    "    y_eval_pred_class = np.argmax(y_eval_csp_pred, axis=1) + 1\n",
    "\n",
    "    acc_train = accuracy_score(y_train, y_train_pred_class)\n",
    "    kappa_train = cohen_kappa_score(y_train, y_train_pred_class)\n",
    "\n",
    "    acc_eval = accuracy_score(y_true, y_eval_pred_class)\n",
    "    kappa_eval = cohen_kappa_score(y_true, y_eval_pred_class)\n",
    "\n",
    "    f1_score_eval = f1_score(y_true, y_eval_pred_class, average='weighted')\n",
    "\n",
    "    current_result = {\n",
    "        'rs': rs,\n",
    "        'lr': lr,\n",
    "        'sr': sr,\n",
    "        'alpha': alpha,\n",
    "        'aggregate': aggregate,\n",
    "        'acc_train': acc_train,\n",
    "        'kappa_train': kappa_train,\n",
    "        'acc_eval': acc_eval,\n",
    "        'kappa_eval': kappa_eval,\n",
    "        'f1_weighted': f1_score_eval\n",
    "    }\n",
    "\n",
    "    if kappa_eval > max_kappa:\n",
    "        max_kappa = kappa_eval\n",
    "\n",
    "    results_list.append(current_result)\n",
    "\n",
    "    pbar.update(1)\n",
    "\n",
    "print(\"Parameter search complete.\")\n",
    "                    \n",
    "df_results = pd.DataFrame(results_list)\n",
    "\n",
    "df_results.to_csv('tuning_results.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "405bfc82",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sorted = df_results.sort_values(by='kappa_eval', ascending=False)\n",
    "\n",
    "print(\"Top 5 Results:\")\n",
    "print(df_sorted.head(5))\n",
    "\n",
    "best_params = df_sorted.iloc[0].to_dict()\n",
    "\n",
    "print(\"\\nBest Parameter Set:\")\n",
    "print(best_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa3cfa79",
   "metadata": {},
   "source": [
    "## Per subject"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0507ba9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "subject_id_ls = [i for i in range(1, 10)]\n",
    "\n",
    "for subject_id in tqdm(subject_id_ls):\n",
    "    # Load data\n",
    "    npz_filename_T = f'./data/train/A0{subject_id}T.npz'\n",
    "    npz_filename_E = f'./data/eval/A0{subject_id}E.npz'\n",
    "\n",
    "    data_T = np.load(npz_filename_T)\n",
    "    data_E = np.load(npz_filename_E)\n",
    "\n",
    "    # \n",
    "    X_train = data_T['X']\n",
    "\n",
    "    # y_train = np.asarray([np.asarray([item-6 for i in range(X_train.shape[1])]) for item in data_T['y']])\n",
    "    y_train = data_T['y'] - 6\n",
    "\n",
    "    X_eval = data_E['X']\n",
    "    y_true = data_E['y_true']\n",
    "\n",
    "    # \n",
    "    X_train = data_T['X']\n",
    "\n",
    "    y_train = data_T['y'] - 6\n",
    "\n",
    "    X_eval = data_E['X']\n",
    "    y_true = data_E['y_true']\n",
    "\n",
    "    lb = LabelBinarizer()\n",
    "\n",
    "    y_train_onehot = lb.fit_transform(y_train)\n",
    "    y_true_onehot = lb.transform(y_true)\n",
    "\n",
    "    csp = CSP(n_components=4, reg=None, log=True, norm_trace=False)\n",
    "\n",
    "    csp = csp.fit(X_train, y_train)\n",
    "\n",
    "    X_train_csp = np.asarray([csp.transform(sample.T) for sample in X_train])\n",
    "    X_eval_csp = np.asarray([csp.transform(sample.T) for sample in X_eval])\n",
    "\n",
    "    aggregate = 'mean'\n",
    "\n",
    "    X_train_csp_states = extract_states(X_train_csp, reservoir, aggregate=aggregate)\n",
    "    X_eval_csp_states = extract_states(X_eval_csp, reservoir, aggregate=aggregate)\n",
    "\n",
    "    readout.fit(X_train_csp_states, y_train_onehot)\n",
    "\n",
    "    y_train_csp_pred = readout.run(X_train_csp_states)\n",
    "    y_eval_csp_pred = readout.run(X_eval_csp_states)\n",
    "\n",
    "    y_train_pred_class = np.argmax(y_train_csp_pred, axis=1) + 1\n",
    "    y_eval_pred_class = np.argmax(y_eval_csp_pred, axis=1) + 1\n",
    "\n",
    "    print(25*'==')\n",
    "    print(f'SUBJECT ID: {subject_id}')\n",
    "    print(f\"Train Accuracy: {accuracy_score(y_train, y_train_pred_class):.4f}\")\n",
    "    print(f'Train Kappa: {cohen_kappa_score(y_train, y_train_pred_class)}')\n",
    "    print(f\"Eval Accuracy: {accuracy_score(y_true, y_eval_pred_class):.4f}\")\n",
    "    print(f'Eval Kappa: {cohen_kappa_score(y_true, y_eval_pred_class)}')\n",
    "\n",
    "    print(\"\\nClassification Report:\")\n",
    "    print(classification_report(y_true, y_eval_pred_class))\n",
    "    \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.11.14)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
