{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8f39ff4d",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "687bdf95",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from mne.decoding import CSP\n",
    "import scipy.io\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score, f1_score, cohen_kappa_score, confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.linear_model import RidgeClassifier\n",
    "from sklearn.metrics import cohen_kappa_score\n",
    "from tqdm import tqdm\n",
    "from sklearn.linear_model import RidgeClassifierCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from pyrcn.echo_state_network import ESNClassifier\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader, TensorDataset\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from tqdm import tqdm\n",
    "import cupy as cp\n",
    "import reservoirpy as rpy\n",
    "from reservoirpy.nodes import Reservoir\n",
    "from reservoirpy.nodes import Ridge\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "import pandas as pd\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "394114c1",
   "metadata": {},
   "source": [
    "## Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "eff740a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "subject_id = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e88ac83",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "6a270150",
   "metadata": {},
   "outputs": [],
   "source": [
    "npz_filename_T = f'./data/train/A0{subject_id}T.npz'\n",
    "npz_filename_E = f'./data/eval/A0{subject_id}E.npz'\n",
    "\n",
    "data_T = np.load(npz_filename_T)\n",
    "data_E = np.load(npz_filename_E)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "d0d4e9f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = data_T['X']\n",
    "\n",
    "# y_train = np.asarray([np.asarray([item-6 for i in range(X_train.shape[1])]) for item in data_T['y']])\n",
    "y_train = data_T['y'] - 6\n",
    "\n",
    "X_eval = data_E['X']\n",
    "y_true = data_E['y_true']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "414d7e49",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((288, 22, 751),\n",
       " (288,),\n",
       " np.float64(4.216004148744056e-05),\n",
       " np.float64(-4.2082318582766146e-05),\n",
       " np.float64(-2.6516604026355054e-09),\n",
       " np.float64(5.388162290701335e-06))"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, y_train.shape, np.max(X_train), np.min(X_train), np.mean(X_train), np.std(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e68239f",
   "metadata": {},
   "source": [
    "## One-Hot encode labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "8cba1b08",
   "metadata": {},
   "outputs": [],
   "source": [
    "lb = LabelBinarizer()\n",
    "\n",
    "y_train_onehot = lb.fit_transform(y_train)\n",
    "y_true_onehot = lb.transform(y_true)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab445594",
   "metadata": {},
   "source": [
    "## CSP Transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "3c8cc5c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing rank from data with rank=None\n",
      "    Using tolerance 5e-05 (2.2e-16 eps * 22 dim * 1e+10  max singular value)\n",
      "    Estimated rank (data): 22\n",
      "    data: rank 22 computed from 22 data channels with 0 projectors\n",
      "Reducing data rank from 22 -> 22\n",
      "Estimating class=1 covariance using EMPIRICAL\n",
      "Done.\n",
      "Estimating class=2 covariance using EMPIRICAL\n",
      "Done.\n",
      "Estimating class=3 covariance using EMPIRICAL\n",
      "Done.\n",
      "Estimating class=4 covariance using EMPIRICAL\n",
      "Done.\n"
     ]
    }
   ],
   "source": [
    "csp = CSP(n_components=4, reg=None, log=True, norm_trace=False)\n",
    "\n",
    "csp = csp.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "4a89f611",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((22, 22), (22, 751))"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "csp.filters_.shape, X_train[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "04daa95b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(751, 22)"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[sample.T.shape for sample in X_train][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "f898e788",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_csp = np.asarray([csp.transform(sample.T) for sample in X_train])\n",
    "X_eval_csp = np.asarray([csp.transform(sample.T) for sample in X_eval])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "83af4361",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((288, 22, 751), (288, 751, 4), (288, 751, 4))"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, X_train_csp.shape, X_eval_csp.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81ed916e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((288, 751, 4),\n",
       " (288,),\n",
       " np.float64(3.9311456914301317),\n",
       " np.float64(-25.50502669610828),\n",
       " np.float64(-1.5510004655988325),\n",
       " np.float64(2.3518185063966763))"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_csp.shape, y_train.shape, np.max(X_train_csp), np.min(X_train_csp), np.mean(X_train_csp), np.std(X_train_csp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c19e10e2",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d6c4a796",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "20d2f549",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def extract_states(X_data, reservoir, aggregate='mean'):\n",
    "#     states_list = []\n",
    "\n",
    "#     pbar = tqdm(range(len(X_data)))\n",
    "\n",
    "#     for i in pbar:\n",
    "#         data = X_data[i].T\n",
    "\n",
    "#         states = []\n",
    "#         for j in range(data.shape[0]):\n",
    "#             input = data[j].reshape(data[j].shape[0], 1)\n",
    "\n",
    "#             state = reservoir.run(input, workers=-1)\n",
    "\n",
    "#             states.append(state)\n",
    "\n",
    "#         if aggregate == 'final':\n",
    "#             feature = states[-1:, :]\n",
    "#         elif aggregate == 'mean':\n",
    "#             feature = np.mean(states, axis=0, keepdims=True)\n",
    "#         elif aggregate == 'concat':\n",
    "#             # Combine multiple statistics\n",
    "#             feature = np.concatenate([\n",
    "#                 states[-1:, :],\n",
    "#                 np.mean(states, axis=0, keepdims=True),\n",
    "#                 np.std(states, axis=0, keepdims=True)\n",
    "#             ], axis=1)\n",
    "        \n",
    "#         states_list.append(feature)\n",
    "    \n",
    "#     return np.vstack(states_list)\n",
    "\n",
    "def extract_states(X_data, reservoir, aggregate='mean'):\n",
    "    states_list = []\n",
    "\n",
    "    for i in range(len(X_data)):\n",
    "        data = X_data[i]\n",
    "\n",
    "        states = reservoir.run(data, workers=-1)\n",
    "\n",
    "        if aggregate == 'final':\n",
    "            feature = states[-1:, :]\n",
    "        elif aggregate == 'mean':\n",
    "            feature = np.mean(states, axis=0, keepdims=True)\n",
    "        elif aggregate == 'concat':\n",
    "            # Combine multiple statistics\n",
    "            feature = np.concatenate([\n",
    "                states[-1:, :],\n",
    "                np.mean(states, axis=0, keepdims=True),\n",
    "                np.std(states, axis=0, keepdims=True)\n",
    "            ], axis=1)\n",
    "        \n",
    "        states_list.append(feature)\n",
    "    \n",
    "    return np.vstack(states_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "915f6e56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy: 0.6354\n",
      "Train Kappa: 0.5138888888888888\n",
      "Eval Accuracy: 0.6146\n",
      "Eval Kappa: 0.48611111111111116\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.67      0.83      0.75        72\n",
      "           2       0.92      0.64      0.75        72\n",
      "           3       0.75      0.04      0.08        72\n",
      "           4       0.47      0.94      0.63        72\n",
      "\n",
      "    accuracy                           0.61       288\n",
      "   macro avg       0.70      0.61      0.55       288\n",
      "weighted avg       0.70      0.61      0.55       288\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rpy.set_seed(42)\n",
    "\n",
    "# Expected format: (time_steps, channels)\n",
    "reservoir = Reservoir(500, lr=0.7, sr=1.5)\n",
    "\n",
    "readout = Ridge(ridge=1e3)\n",
    "\n",
    "aggregate = 'mean'\n",
    "\n",
    "X_train_csp_states = extract_states(X_train_csp, reservoir, aggregate=aggregate)\n",
    "X_eval_csp_states = extract_states(X_eval_csp, reservoir, aggregate=aggregate)\n",
    "\n",
    "readout.fit(X_train_csp_states, y_train_onehot)\n",
    "\n",
    "y_train_csp_pred = readout.run(X_train_csp_states)\n",
    "y_eval_csp_pred = readout.run(X_eval_csp_states)\n",
    "\n",
    "y_train_pred_class = np.argmax(y_train_csp_pred, axis=1) + 1\n",
    "y_eval_pred_class = np.argmax(y_eval_csp_pred, axis=1) + 1\n",
    "\n",
    "print(f\"Train Accuracy: {accuracy_score(y_train, y_train_pred_class):.4f}\")\n",
    "print(f'Train Kappa: {cohen_kappa_score(y_train, y_train_pred_class)}')\n",
    "print(f\"Eval Accuracy: {accuracy_score(y_true, y_eval_pred_class):.4f}\")\n",
    "print(f'Eval Kappa: {cohen_kappa_score(y_true, y_eval_pred_class)}')\n",
    "\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_true, y_eval_pred_class))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69612281",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "# PCA visualization of reservoir states in 3D\n",
    "pca = PCA(n_components=3)\n",
    "X_pca = pca.fit_transform(X_train_csp_states)\n",
    "\n",
    "print(f\"Explained variance ratio: {pca.explained_variance_ratio_}\")\n",
    "print(f\"Total explained variance: {np.sum(pca.explained_variance_ratio_):.3f}\")\n",
    "\n",
    "# Create 3D plot\n",
    "fig = plt.figure(figsize=(12, 10))\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "# Define colors for each class\n",
    "colors = {1: 'red', 2: 'blue', 3: 'green', 4: 'orange'}\n",
    "label_names = {1: 'Left Hand', 2: 'Right Hand', 3: 'Feet', 4: 'Tongue'}\n",
    "\n",
    "# Plot each class\n",
    "for label in np.unique(y_train):\n",
    "    mask = y_train == label\n",
    "    ax.scatter(X_pca[mask, 0], X_pca[mask, 1], X_pca[mask, 2], \n",
    "               c=colors[label], label=label_names[label], alpha=0.7, s=50)\n",
    "\n",
    "ax.set_title('3D PCA of Reservoir States')\n",
    "ax.set_xlabel(f'PC1 ({pca.explained_variance_ratio_[0]:.2%} variance)')\n",
    "ax.set_ylabel(f'PC2 ({pca.explained_variance_ratio_[1]:.2%} variance)')\n",
    "ax.set_zlabel(f'PC3 ({pca.explained_variance_ratio_[2]:.2%} variance)')\n",
    "ax.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "4e8a085d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((288, 4, 500), (288, 4))"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_csp_states.shape, y_train_onehot.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "73ed9859",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'shape'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[137]\u001b[39m\u001b[32m, line 43\u001b[39m\n\u001b[32m     28\u001b[39m     all_trial_predictions.append(trial_predictions)\n\u001b[32m     30\u001b[39m     \u001b[38;5;66;03m# # Slide the 2-second window\u001b[39;00m\n\u001b[32m     31\u001b[39m     \u001b[38;5;66;03m# state = np.zeros()\u001b[39;00m\n\u001b[32m     32\u001b[39m     \u001b[38;5;66;03m# for start in range(0, trial_data.shape[2] - window_samples, step_samples):\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m     40\u001b[39m     \u001b[38;5;66;03m#     prediction = clf.predict(window_data_reshaped)\u001b[39;00m\n\u001b[32m     41\u001b[39m     \u001b[38;5;66;03m#     trial_predictions.append(prediction[0])\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m43\u001b[39m \u001b[43mall_trial_predictions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mshape\u001b[49m\n",
      "\u001b[31mAttributeError\u001b[39m: 'list' object has no attribute 'shape'"
     ]
    }
   ],
   "source": [
    "window_samples = 100  # 2 seconds @ 250 Hz\n",
    "step_samples = 10     # 40ms step, as per winner's PDF [cite: 145]\n",
    "\n",
    "all_trial_predictions = []\n",
    "\n",
    "washout_time = 125\n",
    "\n",
    "sample_step = 10\n",
    "\n",
    "# Loop over each trial\n",
    "for trial_data in X_eval_csp:\n",
    "    states = []\n",
    "    trial_predictions = []\n",
    "\n",
    "    for i in range(0, trial_data.shape[0], sample_step):\n",
    "        input = trial_data[i].reshape(1, trial_data[i].shape[0])\n",
    "        \n",
    "        state = reservoir.run(input)\n",
    "\n",
    "        if i >= washout_time:\n",
    "            states.append(state)\n",
    "\n",
    "            mean_state = np.mean(states, axis=0, keepdims=True)\n",
    "\n",
    "            y_pred = readout.run(X_train_csp_states)\n",
    "            y_pred_class = np.argmax(y_pred, axis=1) + 1\n",
    "\n",
    "            trial_predictions.append(y_pred_class)\n",
    "\n",
    "    all_trial_predictions.append(trial_predictions)\n",
    "\n",
    "    # # Slide the 2-second window\n",
    "    # state = np.zeros()\n",
    "    # for start in range(0, trial_data.shape[2] - window_samples, step_samples):\n",
    "    #     end = start + window_samples\n",
    "    #     window_data = trial_data[:, start:end]\n",
    "\n",
    "    #     # Reshape for the pipeline: (1, n_channels, n_samples)\n",
    "    #     window_data_reshaped = window_data.reshape(1, *window_data.shape)\n",
    "        \n",
    "    #     # Make a prediction using our trained causal model\n",
    "    #     prediction = clf.predict(window_data_reshaped)\n",
    "    #     trial_predictions.append(prediction[0])\n",
    "\n",
    "all_trial_predictions.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77c890a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transpose the prediction matrix so we can score each time point\n",
    "predictions_by_time = np.array(all_trial_predictions).T\n",
    "\n",
    "kappa_scores = []\n",
    "for y_pred_at_time_t in predictions_by_time:\n",
    "    # Map MNE labels (769...) to simple labels (1...)\n",
    "    y_pred_mapped = np.array([pred for pred in y_pred_at_time_t])\n",
    "    \n",
    "    # Calculate kappa for this single time slice\n",
    "    kappa = cohen_kappa_score(y_true, y_pred_mapped)\n",
    "    kappa_scores.append(kappa)\n",
    "    acc = accuracy_score(y_true, y_pred_mapped)\n",
    "\n",
    "# --- 5. Find the Final Score ---\n",
    "max_kappa = np.max(kappa_scores)\n",
    "max_acc = np.max(acc)\n",
    "\n",
    "print(f\"Time course of Kappa calculated.\")\n",
    "print(f\"Maximum Kappa value: {max_kappa:.3f}\")\n",
    "print(f\"Maximum Accuracy value: {max_acc:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee600292",
   "metadata": {},
   "source": [
    "## Fine Tune"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2415d42a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(rs, lr, sr, alpha):\n",
    "    reservoir = Reservoir(rs, lr=lr, sr=sr)\n",
    "    readout = Ridge(ridge=alpha)\n",
    "\n",
    "    return reservoir, readout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed71fbe9",
   "metadata": {},
   "outputs": [],
   "source": [
    "rs_ls = [500, 750]\n",
    "alpha_ls = [0.1, 1.0, 10.0, 100.0, 1000.0, 10000.0]\n",
    "lr_ls = [0.3, 0.5, 0.7]\n",
    "sr_ls = [0.5, 0.7, 0.9, 1.2, 1.5]\n",
    "aggregate_ls = ['final', 'mean', 'concat']\n",
    "\n",
    "rpy.set_seed(42)\n",
    "\n",
    "results_list = []\n",
    "\n",
    "model_params = list(itertools.product(rs_ls, lr_ls, sr_ls, alpha_ls, aggregate_ls))\n",
    "total_iterations = len(model_params)\n",
    "\n",
    "pbar = tqdm(total=total_iterations, desc=\"Grid Search Progress\")\n",
    "\n",
    "for (rs, lr, sr, alpha, aggregate) in model_params:\n",
    "    params = {'rs': rs, 'lr': lr, 'sr': sr, 'alpha': alpha}\n",
    "    pbar.set_postfix({'rs': rs, 'lr': lr, 'sr': sr, 'alpha': alpha})\n",
    "    # print('-')\n",
    "\n",
    "    reservoir, readout = build_model(rs=rs, lr=lr, sr=sr, alpha=alpha)\n",
    "\n",
    "    X_train_csp_states = extract_states(X_train_csp, reservoir, aggregate=aggregate)\n",
    "    X_eval_csp_states = extract_states(X_eval_csp, reservoir, aggregate=aggregate)\n",
    "\n",
    "    readout.fit(X_train_csp_states, y_train_onehot)\n",
    "\n",
    "    y_train_csp_pred = readout.run(X_train_csp_states)\n",
    "    y_eval_csp_pred = readout.run(X_eval_csp_states)\n",
    "\n",
    "    y_train_pred_class = np.argmax(y_train_csp_pred, axis=1) + 1\n",
    "    y_eval_pred_class = np.argmax(y_eval_csp_pred, axis=1) + 1\n",
    "\n",
    "    acc_train = accuracy_score(y_train, y_train_pred_class)\n",
    "    kappa_train = cohen_kappa_score(y_train, y_train_pred_class)\n",
    "\n",
    "    acc_eval = accuracy_score(y_true, y_eval_pred_class)\n",
    "    kappa_eval = cohen_kappa_score(y_true, y_eval_pred_class)\n",
    "\n",
    "    f1_score_eval = f1_score(y_true, y_eval_pred_class, average='weighted')\n",
    "\n",
    "    current_result = {\n",
    "        'rs': rs,\n",
    "        'lr': lr,\n",
    "        'sr': sr,\n",
    "        'alpha': alpha,\n",
    "        'aggregate': aggregate,\n",
    "        'acc_train': acc_train,\n",
    "        'kappa_train': kappa_train,\n",
    "        'acc_eval': acc_eval,\n",
    "        'kappa_eval': kappa_eval,\n",
    "        'f1_weighted': f1_score_eval\n",
    "    }\n",
    "\n",
    "    print(f'{kappa_eval}')\n",
    "\n",
    "    results_list.append(current_result)\n",
    "\n",
    "    pbar.update(1)\n",
    "\n",
    "print(\"Parameter search complete.\")\n",
    "                    \n",
    "df_results = pd.DataFrame(results_list)\n",
    "\n",
    "# df_results.to_csv('tuning_results.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "405bfc82",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sorted = df_results.sort_values(by='kappa_eval', ascending=False)\n",
    "\n",
    "print(\"Top 5 Results:\")\n",
    "print(df_sorted.head(5))\n",
    "\n",
    "best_params = df_sorted.iloc[0].to_dict()\n",
    "\n",
    "print(\"\\nBest Parameter Set:\")\n",
    "print(best_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa3cfa79",
   "metadata": {},
   "source": [
    "## Per subject"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0507ba9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "subject_id_ls = [i for i in range(1, 10)]\n",
    "\n",
    "rpy.set_seed(42)\n",
    "\n",
    "reservoir = Reservoir(1000, lr=0.5, sr=1.5)\n",
    "\n",
    "readout = Ridge(ridge=1e2)\n",
    "\n",
    "for subject_id in tqdm(subject_id_ls):\n",
    "    # Load data\n",
    "    npz_filename_T = f'./data/train/A0{subject_id}T.npz'\n",
    "    npz_filename_E = f'./data/eval/A0{subject_id}E.npz'\n",
    "\n",
    "    data_T = np.load(npz_filename_T)\n",
    "    data_E = np.load(npz_filename_E)\n",
    "\n",
    "    # \n",
    "    X_train = data_T['X']\n",
    "\n",
    "    # y_train = np.asarray([np.asarray([item-6 for i in range(X_train.shape[1])]) for item in data_T['y']])\n",
    "    y_train = data_T['y'] - 6\n",
    "\n",
    "    X_eval = data_E['X']\n",
    "    y_true = data_E['y_true']\n",
    "\n",
    "    # \n",
    "    X_train = data_T['X']\n",
    "\n",
    "    y_train = data_T['y'] - 6\n",
    "\n",
    "    X_eval = data_E['X']\n",
    "    y_true = data_E['y_true']\n",
    "\n",
    "    lb = LabelBinarizer()\n",
    "\n",
    "    y_train_onehot = lb.fit_transform(y_train)\n",
    "    y_true_onehot = lb.transform(y_true)\n",
    "\n",
    "    csp = CSP(n_components=4, reg=None, log=True, norm_trace=False)\n",
    "\n",
    "    csp = csp.fit(X_train, y_train)\n",
    "\n",
    "    X_train_csp = np.asarray([csp.transform(sample.T) for sample in X_train]).transpose(0, 2, 1)\n",
    "    X_eval_csp = np.asarray([csp.transform(sample.T) for sample in X_eval]).transpose(0, 2, 1)\n",
    "\n",
    "    aggregate = 'concat'\n",
    "\n",
    "    X_train_csp_states = extract_states(X_train_csp, reservoir, aggregate=aggregate)\n",
    "    X_eval_csp_states = extract_states(X_eval_csp, reservoir, aggregate=aggregate)\n",
    "\n",
    "    readout.fit(X_train_csp_states, y_train_onehot)\n",
    "\n",
    "    y_train_csp_pred = readout.run(X_train_csp_states)\n",
    "    y_eval_csp_pred = readout.run(X_eval_csp_states)\n",
    "\n",
    "    y_train_pred_class = np.argmax(y_train_csp_pred, axis=1) + 1\n",
    "    y_eval_pred_class = np.argmax(y_eval_csp_pred, axis=1) + 1\n",
    "\n",
    "    print(25*'==')\n",
    "    print(f'SUBJECT ID: {subject_id}')\n",
    "    print(f\"Train Accuracy: {accuracy_score(y_train, y_train_pred_class):.4f}\")\n",
    "    print(f'Train Kappa: {cohen_kappa_score(y_train, y_train_pred_class)}')\n",
    "    print(f\"Eval Accuracy: {accuracy_score(y_true, y_eval_pred_class):.4f}\")\n",
    "    print(f'Eval Kappa: {cohen_kappa_score(y_true, y_eval_pred_class)}')\n",
    "\n",
    "    print(\"\\nClassification Report:\")\n",
    "    print(classification_report(y_true, y_eval_pred_class))\n",
    "    \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.11.14)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
