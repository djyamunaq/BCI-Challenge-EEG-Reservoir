{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8f39ff4d",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "687bdf95",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from mne.decoding import CSP\n",
    "import scipy.io\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score, f1_score, cohen_kappa_score, confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.linear_model import RidgeClassifier\n",
    "from sklearn.metrics import cohen_kappa_score\n",
    "from tqdm import tqdm\n",
    "from sklearn.linear_model import RidgeClassifierCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from pyrcn.echo_state_network import ESNClassifier\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader, TensorDataset\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from tqdm import tqdm\n",
    "import cupy as cp\n",
    "import reservoirpy as rpy\n",
    "from reservoirpy.nodes import Reservoir\n",
    "from reservoirpy.nodes import Ridge\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "import pandas as pd\n",
    "import itertools\n",
    "import plotly.express as px\n",
    "from sklearn.decomposition import PCA\n",
    "import numpy as np\n",
    "from reservoirpy.model import Model\n",
    "from sklearn.metrics import accuracy_score\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "394114c1",
   "metadata": {},
   "source": [
    "## Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "eff740a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "subject_id = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e88ac83",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6a270150",
   "metadata": {},
   "outputs": [],
   "source": [
    "npz_filename_T = f'./data/train/A0{subject_id}T.npz'\n",
    "npz_filename_E = f'./data/eval/A0{subject_id}E.npz'\n",
    "\n",
    "data_T = np.load(npz_filename_T)\n",
    "data_E = np.load(npz_filename_E)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d0d4e9f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_left = data_T['X_left']\n",
    "X_train_right = data_T['X_right']\n",
    "X_train_central = data_T['X_central']\n",
    "\n",
    "# y_train = np.asarray([np.asarray([item-6 for i in range(X_train.shape[1])]) for item in data_T['y']])\n",
    "y_train = data_T['y'] - 6\n",
    "\n",
    "X_eval_left = data_E['X_left']\n",
    "X_eval_right = data_E['X_right']\n",
    "X_eval_central = data_E['X_central']\n",
    "y_true = data_E['y_true']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b2811234",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((288, 8, 751), (288, 8, 751), (288, 6, 751))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_left.shape, X_train_right.shape, X_train_central.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1a669fef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((288, 8, 751), (288, 8, 751), (288, 6, 751), (288, 1))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_eval_left.shape, X_eval_right.shape, X_eval_central.shape, y_true.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e68239f",
   "metadata": {},
   "source": [
    "## One-Hot encode labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8cba1b08",
   "metadata": {},
   "outputs": [],
   "source": [
    "lb = LabelBinarizer()\n",
    "\n",
    "y_train_onehot = lb.fit_transform(y_train)\n",
    "y_true_onehot = lb.transform(y_true)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab445594",
   "metadata": {},
   "source": [
    "## CSP Transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3c8cc5c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing rank from data with rank=None\n",
      "    Using tolerance 2.2e-05 (2.2e-16 eps * 8 dim * 1.2e+10  max singular value)\n",
      "    Estimated rank (data): 8\n",
      "    data: rank 8 computed from 8 data channels with 0 projectors\n",
      "Reducing data rank from 8 -> 8\n",
      "Estimating class=1 covariance using EMPIRICAL\n",
      "Done.\n",
      "Estimating class=2 covariance using EMPIRICAL\n",
      "Done.\n",
      "Estimating class=3 covariance using EMPIRICAL\n",
      "Done.\n",
      "Estimating class=4 covariance using EMPIRICAL\n",
      "Done.\n",
      "Computing rank from data with rank=None\n",
      "    Using tolerance 2.3e-05 (2.2e-16 eps * 8 dim * 1.3e+10  max singular value)\n",
      "    Estimated rank (data): 8\n",
      "    data: rank 8 computed from 8 data channels with 0 projectors\n",
      "Reducing data rank from 8 -> 8\n",
      "Estimating class=1 covariance using EMPIRICAL\n",
      "Done.\n",
      "Estimating class=2 covariance using EMPIRICAL\n",
      "Done.\n",
      "Estimating class=3 covariance using EMPIRICAL\n",
      "Done.\n",
      "Estimating class=4 covariance using EMPIRICAL\n",
      "Done.\n",
      "Computing rank from data with rank=None\n",
      "    Using tolerance 1.5e-05 (2.2e-16 eps * 6 dim * 1.1e+10  max singular value)\n",
      "    Estimated rank (data): 6\n",
      "    data: rank 6 computed from 6 data channels with 0 projectors\n",
      "Reducing data rank from 6 -> 6\n",
      "Estimating class=1 covariance using EMPIRICAL\n",
      "Done.\n",
      "Estimating class=2 covariance using EMPIRICAL\n",
      "Done.\n",
      "Estimating class=3 covariance using EMPIRICAL\n",
      "Done.\n",
      "Estimating class=4 covariance using EMPIRICAL\n",
      "Done.\n"
     ]
    }
   ],
   "source": [
    "# LEFT TRANSFORMATION\n",
    "csp_left = CSP(n_components=4, reg=None, log=True, norm_trace=False)\n",
    "csp_left = csp_left.fit(X_train_left, y_train)\n",
    "\n",
    "X_train_left_csp = np.asarray([csp_left.transform(sample.T) for sample in X_train_left])\n",
    "X_eval_left_csp = np.asarray([csp_left.transform(sample.T) for sample in X_eval_left])\n",
    "\n",
    "# RIGHT TRANSFORMATION\n",
    "csp_right = CSP(n_components=4, reg=None, log=True, norm_trace=False)\n",
    "csp_right = csp_right.fit(X_train_right, y_train)\n",
    "\n",
    "X_train_right_csp = np.asarray([csp_right.transform(sample.T) for sample in X_train_right])\n",
    "X_eval_right_csp = np.asarray([csp_right.transform(sample.T) for sample in X_eval_right])\n",
    "\n",
    "# CENTRAL TRANSFORMATION\n",
    "csp_central = CSP(n_components=4, reg=None, log=True, norm_trace=False)\n",
    "csp_central = csp_central.fit(X_train_central, y_train)\n",
    "\n",
    "X_train_central_csp = np.asarray([csp_central.transform(sample.T) for sample in X_train_central])\n",
    "X_eval_central_csp = np.asarray([csp_central.transform(sample.T) for sample in X_eval_central])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4a89f611",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((288, 751, 4), (288, 751, 4), (288, 751, 4))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_left_csp.shape, X_train_right_csp.shape, X_train_central_csp.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4712e66b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((288, 751, 4), (288, 751, 4), (288, 751, 4))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_eval_left_csp.shape, X_eval_right_csp.shape, X_eval_central_csp.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c19e10e2",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d6c4a796",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20d2f549",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_states(X_data, reservoir, aggregate='mean'):\n",
    "    states_list = []\n",
    "\n",
    "    for i in range(len(X_data)):\n",
    "        data = X_data[i]\n",
    "\n",
    "        states = reservoir.run(data, workers=-1)\n",
    "\n",
    "        if aggregate == 'final':\n",
    "            feature = states[-1:, :]\n",
    "        elif aggregate == 'mean':\n",
    "            feature = np.mean(states, axis=0, keepdims=True)\n",
    "        elif aggregate == 'concat':\n",
    "            # Combine multiple statistics\n",
    "            feature = np.concatenate([\n",
    "                states[-1:, :],\n",
    "                np.mean(states, axis=0, keepdims=True),\n",
    "                np.std(states, axis=0, keepdims=True)\n",
    "            ], axis=1)\n",
    "        \n",
    "        states_list.append(feature)\n",
    "    \n",
    "    return np.vstack(states_list)\n",
    "\n",
    "def extract_states_partial(X_data, reservoir, aggregate='mean'):\n",
    "    states_list = []\n",
    "\n",
    "    # print(X_data.shape)\n",
    "    for i in range(len(X_data)):\n",
    "        data = X_data[i]\n",
    "\n",
    "        states = reservoir.run(data, workers=-1)\n",
    "\n",
    "        # print(data.shape, states.shape)\n",
    "        # break\n",
    "\n",
    "        # if aggregate == 'final':\n",
    "        #     feature = states[-1:, :]\n",
    "        # elif aggregate == 'mean':\n",
    "        #     feature = np.mean(states, axis=0, keepdims=True)\n",
    "        # elif aggregate == 'concat':\n",
    "        #     # Combine multiple statistics\n",
    "        #     feature = np.concatenate([\n",
    "        #         states[-1:, :],\n",
    "        #         np.mean(states, axis=0, keepdims=True),\n",
    "        #         np.std(states, axis=0, keepdims=True)\n",
    "        #     ], axis=1)\n",
    "        \n",
    "        states_list.append(states)\n",
    "    \n",
    "    return np.asarray(states_list)\n",
    "    return np.vstack(states_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9d1832f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_left_csp_states = None\n",
    "X_eval_left_csp_states = None\n",
    "\n",
    "X_train_right_csp_states = None\n",
    "X_eval_right_csp_states = None\n",
    "\n",
    "X_train_central_csp_states = None\n",
    "X_eval_central_csp_states = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "915f6e56",
   "metadata": {},
   "outputs": [],
   "source": [
    "rpy.set_seed(42)\n",
    "\n",
    "rs = 500\n",
    "lr = 0.9\n",
    "sr = 2.0\n",
    "\n",
    "# Expected format: (time_steps, channels)\n",
    "reservoir_left = Reservoir(rs, lr=lr, sr=sr)\n",
    "reservoir_right = Reservoir(rs, lr=lr, sr=sr)\n",
    "reservoir_central = Reservoir(rs, lr=lr, sr=sr)\n",
    "reservoir_integrate = Reservoir(rs, lr=lr, sr=sr)\n",
    "\n",
    "aggregate = 'mean'\n",
    "\n",
    "X_train_left_csp_states = extract_states_partial(X_train_left_csp, reservoir_left, aggregate=aggregate)\n",
    "X_eval_left_csp_states = extract_states_partial(X_eval_left_csp, reservoir_left, aggregate=aggregate)\n",
    "\n",
    "X_train_right_csp_states = extract_states_partial(X_train_right_csp, reservoir_right, aggregate=aggregate)\n",
    "X_eval_right_csp_states = extract_states_partial(X_eval_right_csp, reservoir_right, aggregate=aggregate)\n",
    "\n",
    "X_train_central_csp_states = extract_states_partial(X_train_central_csp, reservoir_central, aggregate=aggregate)\n",
    "X_eval_central_csp_states = extract_states_partial(X_eval_central_csp, reservoir_central, aggregate=aggregate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a02f01ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((288, 751, 500), (288, 751, 500), (288, 751, 500))"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_left_csp_states.shape, X_train_right_csp_states.shape, X_train_central_csp_states.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "faf03826",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((288, 751, 1500), (288, 751, 1500), (288, 4))"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_integrate = np.concat((X_train_left_csp_states, X_train_right_csp_states, X_train_central_csp_states), axis=2)\n",
    "X_eval_integrate = np.concat((X_eval_left_csp_states, X_eval_right_csp_states, X_eval_central_csp_states), axis=2)\n",
    "\n",
    "# X_train_integrate = X_train_integrate.reshape(X_train_integrate.shape[0], 1, X_train_integrate.shape[1])\n",
    "# X_eval_integrate = X_eval_integrate.reshape(X_eval_integrate.shape[0], 1, X_eval_integrate.shape[1])\n",
    "\n",
    "X_train_integrate.shape, X_eval_integrate.shape, y_train_onehot.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "6e21af84",
   "metadata": {},
   "outputs": [],
   "source": [
    "integrated_train_states = extract_states(X_train_integrate, reservoir_integrate, aggregate=aggregate)\n",
    "integrated_eval_states = extract_states(X_eval_integrate, reservoir_integrate, aggregate=aggregate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "eb4a055c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((288, 500), (288, 500))"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "integrated_train_states.shape, integrated_eval_states.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c6ccbe4c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Ridge(ridge:10.0, input_dim:500, output_dim:4)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "readout = Ridge(ridge=1e1)\n",
    "\n",
    "readout.fit(integrated_train_states, y_train_onehot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "01705479",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy: 1.0000\n",
      "Train Kappa: 1.0\n",
      "Eval Accuracy: 0.2917\n",
      "Eval Kappa: 0.05555555555555558\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.36      0.39      0.37        72\n",
      "           2       0.23      0.21      0.22        72\n",
      "           3       0.31      0.36      0.33        72\n",
      "           4       0.24      0.21      0.22        72\n",
      "\n",
      "    accuracy                           0.29       288\n",
      "   macro avg       0.29      0.29      0.29       288\n",
      "weighted avg       0.29      0.29      0.29       288\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_train_csp_pred = readout.run(integrated_train_states)\n",
    "y_eval_csp_pred = readout.run(integrated_eval_states)\n",
    "\n",
    "y_train_pred_class = np.argmax(y_train_csp_pred, axis=1) + 1\n",
    "y_eval_pred_class = np.argmax(y_eval_csp_pred, axis=1) + 1\n",
    "\n",
    "print(f\"Train Accuracy: {accuracy_score(y_train, y_train_pred_class):.4f}\")\n",
    "print(f'Train Kappa: {cohen_kappa_score(y_train, y_train_pred_class)}')\n",
    "print(f\"Eval Accuracy: {accuracy_score(y_true, y_eval_pred_class):.4f}\")\n",
    "print(f'Eval Kappa: {cohen_kappa_score(y_true, y_eval_pred_class)}')\n",
    "\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_true, y_eval_pred_class))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69612281",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "\n",
    "# 1. Your original PCA (unchanged)\n",
    "pca = PCA(n_components=3)\n",
    "X_pca = pca.fit_transform(X_train_csp_states)\n",
    "\n",
    "print(f\"Explained variance ratio: {pca.explained_variance_ratio_}\")\n",
    "print(f\"Total explained variance: {np.sum(pca.explained_variance_ratio_):.3f}\")\n",
    "\n",
    "# 2. Define labels and colors (unchanged)\n",
    "label_names = {1: 'Left Hand', 2: 'Right Hand', 3: 'Feet', 4: 'Tongue'}\n",
    "colors = {1: 'red', 2: 'blue', 3: 'green', 4: 'orange'}\n",
    "\n",
    "# 3. Prepare data for Plotly\n",
    "# Create a DataFrame from your PCA results\n",
    "df_pca = pd.DataFrame(X_pca, columns=['PC1', 'PC2', 'PC3'])\n",
    "df_pca['label'] = y_train\n",
    "\n",
    "# Map numeric labels to meaningful string names (better for legends)\n",
    "df_pca['Class'] = df_pca['label'].map(label_names)\n",
    "\n",
    "# 4. Create the color map for Plotly\n",
    "# This maps the *string name* (e.g., 'Left Hand') to the *color* (e.g., 'red')\n",
    "color_discrete_map = {label_names[key]: colors[key] for key in label_names}\n",
    "\n",
    "# 5. Create the interactive 3D plot\n",
    "fig = px.scatter_3d(\n",
    "    df_pca,\n",
    "    x='PC1',\n",
    "    y='PC2',\n",
    "    z='PC3',\n",
    "    color='Class',  # Column to use for coloring\n",
    "    color_discrete_map=color_discrete_map, # Apply your specific colors\n",
    "    title='Interactive 3D PCA of Reservoir States',\n",
    "    \n",
    "    # Add the variance info to the axis labels\n",
    "    labels={\n",
    "        'PC1': f'PC1 ({pca.explained_variance_ratio_[0]:.2%})',\n",
    "        'PC2': f'PC2 ({pca.explained_variance_ratio_[1]:.2%})',\n",
    "        'PC3': f'PC3 ({pca.explained_variance_ratio_[2]:.2%})'\n",
    "    },\n",
    "    \n",
    "    # Customize what you see on hover\n",
    "    hover_data={'Class': True, 'label': False, 'PC1': ':.3f', 'PC2': ':.3f', 'PC3': ':.3f'}\n",
    ")\n",
    "\n",
    "# Optional: Make markers smaller to match your 's=50' (Plotly's default is a bit larger)\n",
    "fig.update_traces(marker=dict(size=4, opacity=0.7))\n",
    "\n",
    "# 6. Show the figure\n",
    "# In a VSCode Notebook, this will render the fully interactive plot\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e8a085d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_csp_states.shape, y_train_onehot.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73ed9859",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_trial_predictions = []\n",
    "\n",
    "washout_time = 125\n",
    "\n",
    "sample_step = 10\n",
    "\n",
    "# Loop over each trial\n",
    "for trial_data in X_eval_csp:\n",
    "    states = []\n",
    "    trial_predictions = []\n",
    "\n",
    "    for i in range(0, trial_data.shape[0], sample_step):\n",
    "        input = trial_data[i].reshape(1, trial_data[i].shape[0])\n",
    "        \n",
    "        state = reservoir.run(input)\n",
    "\n",
    "        if i >= washout_time:\n",
    "            states.append(state)\n",
    "\n",
    "            mean_state = np.mean(states, axis=0, keepdims=True)\n",
    "\n",
    "            y_pred = readout.run(mean_state).flatten()\n",
    "            y_pred_class = np.argmax(y_pred) + 1\n",
    "\n",
    "\n",
    "            trial_predictions.append(y_pred_class)\n",
    "\n",
    "    all_trial_predictions.append(trial_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "641c5827",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array(all_trial_predictions).T.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77c890a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transpose the prediction matrix so we can score each time point\n",
    "predictions_by_time = np.array(all_trial_predictions).T\n",
    "\n",
    "kappa_scores = []\n",
    "for y_pred_at_time_t in predictions_by_time:\n",
    "    y_pred_mapped = np.array([pred for pred in y_pred_at_time_t])\n",
    "    \n",
    "    kappa = cohen_kappa_score(y_true, y_pred_mapped)\n",
    "    kappa_scores.append(kappa)\n",
    "    acc = accuracy_score(y_true, y_pred_mapped)\n",
    "\n",
    "# --- 5. Find the Final Score ---\n",
    "max_kappa = np.max(kappa_scores)\n",
    "max_acc = np.max(acc)\n",
    "\n",
    "print(f\"Time course of Kappa calculated.\")\n",
    "print(f\"Maximum Kappa value: {max_kappa:.3f}\")\n",
    "print(f\"Maximum Accuracy value: {max_acc:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bea61693",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(kappa_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee600292",
   "metadata": {},
   "source": [
    "## Fine Tune"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2415d42a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(rs, lr, sr, alpha):\n",
    "    reservoir = Reservoir(rs, lr=lr, sr=sr)\n",
    "    readout = Ridge(ridge=alpha)\n",
    "\n",
    "    return reservoir, readout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed71fbe9",
   "metadata": {},
   "outputs": [],
   "source": [
    "rs_ls = [500, 1000, 1500]\n",
    "alpha_ls = [1e0, 1e2, 1e4]\n",
    "lr_ls = [0.3, 0.6, 0.9]\n",
    "sr_ls = [0.7, 0.9, 1.2, 1.5, 2.0]\n",
    "aggregate_ls = ['final', 'mean', 'concat']\n",
    "\n",
    "rpy.set_seed(42)\n",
    "\n",
    "results_list = []\n",
    "\n",
    "model_params = list(itertools.product(rs_ls, lr_ls, sr_ls, alpha_ls, aggregate_ls))\n",
    "total_iterations = len(model_params)\n",
    "\n",
    "pbar = tqdm(total=total_iterations, desc=\"Grid Search Progress\")\n",
    "\n",
    "max_kappa = -1\n",
    "\n",
    "for (rs, lr, sr, alpha, aggregate) in model_params:\n",
    "    params = {'max_kappa': max_kappa, 'rs': rs, 'lr': lr, 'sr': sr, 'alpha': alpha}\n",
    "    pbar.set_postfix(params)\n",
    "\n",
    "    reservoir, readout = build_model(rs=rs, lr=lr, sr=sr, alpha=alpha)\n",
    "\n",
    "    X_train_csp_states = extract_states(X_train_csp, reservoir, aggregate=aggregate)\n",
    "    X_eval_csp_states = extract_states(X_eval_csp, reservoir, aggregate=aggregate)\n",
    "\n",
    "    readout.fit(X_train_csp_states, y_train_onehot)\n",
    "\n",
    "    y_train_csp_pred = readout.run(X_train_csp_states)\n",
    "    y_eval_csp_pred = readout.run(X_eval_csp_states)\n",
    "\n",
    "    y_train_pred_class = np.argmax(y_train_csp_pred, axis=1) + 1\n",
    "    y_eval_pred_class = np.argmax(y_eval_csp_pred, axis=1) + 1\n",
    "\n",
    "    acc_train = accuracy_score(y_train, y_train_pred_class)\n",
    "    kappa_train = cohen_kappa_score(y_train, y_train_pred_class)\n",
    "\n",
    "    acc_eval = accuracy_score(y_true, y_eval_pred_class)\n",
    "    kappa_eval = cohen_kappa_score(y_true, y_eval_pred_class)\n",
    "\n",
    "    f1_score_eval = f1_score(y_true, y_eval_pred_class, average='weighted')\n",
    "\n",
    "    current_result = {\n",
    "        'rs': rs,\n",
    "        'lr': lr,\n",
    "        'sr': sr,\n",
    "        'alpha': alpha,\n",
    "        'aggregate': aggregate,\n",
    "        'acc_train': acc_train,\n",
    "        'kappa_train': kappa_train,\n",
    "        'acc_eval': acc_eval,\n",
    "        'kappa_eval': kappa_eval,\n",
    "        'f1_weighted': f1_score_eval\n",
    "    }\n",
    "\n",
    "    \n",
    "    if kappa_eval > max_kappa:\n",
    "        max_kappa = kappa_eval\n",
    "\n",
    "    results_list.append(current_result)\n",
    "\n",
    "    pbar.update(1)\n",
    "\n",
    "print(\"Parameter search complete.\")\n",
    "                    \n",
    "df_results = pd.DataFrame(results_list)\n",
    "\n",
    "df_results.to_csv('tuning_results.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "405bfc82",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sorted = df_results.sort_values(by='kappa_eval', ascending=False)\n",
    "\n",
    "print(\"Top 5 Results:\")\n",
    "print(df_sorted.head(5))\n",
    "\n",
    "best_params = df_sorted.iloc[0].to_dict()\n",
    "\n",
    "print(\"\\nBest Parameter Set:\")\n",
    "print(best_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa3cfa79",
   "metadata": {},
   "source": [
    "## Per subject"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0507ba9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "subject_id_ls = [i for i in range(1, 10)]\n",
    "\n",
    "for subject_id in tqdm(subject_id_ls):\n",
    "    # Load data\n",
    "    npz_filename_T = f'./data/train/A0{subject_id}T.npz'\n",
    "    npz_filename_E = f'./data/eval/A0{subject_id}E.npz'\n",
    "\n",
    "    data_T = np.load(npz_filename_T)\n",
    "    data_E = np.load(npz_filename_E)\n",
    "\n",
    "    # \n",
    "    X_train = data_T['X']\n",
    "\n",
    "    # y_train = np.asarray([np.asarray([item-6 for i in range(X_train.shape[1])]) for item in data_T['y']])\n",
    "    y_train = data_T['y'] - 6\n",
    "\n",
    "    X_eval = data_E['X']\n",
    "    y_true = data_E['y_true']\n",
    "\n",
    "    # \n",
    "    X_train = data_T['X']\n",
    "\n",
    "    y_train = data_T['y'] - 6\n",
    "\n",
    "    X_eval = data_E['X']\n",
    "    y_true = data_E['y_true']\n",
    "\n",
    "    lb = LabelBinarizer()\n",
    "\n",
    "    y_train_onehot = lb.fit_transform(y_train)\n",
    "    y_true_onehot = lb.transform(y_true)\n",
    "\n",
    "    csp = CSP(n_components=4, reg=None, log=True, norm_trace=False)\n",
    "\n",
    "    csp = csp.fit(X_train, y_train)\n",
    "\n",
    "    X_train_csp = np.asarray([csp.transform(sample.T) for sample in X_train])\n",
    "    X_eval_csp = np.asarray([csp.transform(sample.T) for sample in X_eval])\n",
    "\n",
    "    aggregate = 'mean'\n",
    "\n",
    "    X_train_csp_states = extract_states(X_train_csp, reservoir, aggregate=aggregate)\n",
    "    X_eval_csp_states = extract_states(X_eval_csp, reservoir, aggregate=aggregate)\n",
    "\n",
    "    readout.fit(X_train_csp_states, y_train_onehot)\n",
    "\n",
    "    y_train_csp_pred = readout.run(X_train_csp_states)\n",
    "    y_eval_csp_pred = readout.run(X_eval_csp_states)\n",
    "\n",
    "    y_train_pred_class = np.argmax(y_train_csp_pred, axis=1) + 1\n",
    "    y_eval_pred_class = np.argmax(y_eval_csp_pred, axis=1) + 1\n",
    "\n",
    "    print(25*'==')\n",
    "    print(f'SUBJECT ID: {subject_id}')\n",
    "    print(f\"Train Accuracy: {accuracy_score(y_train, y_train_pred_class):.4f}\")\n",
    "    print(f'Train Kappa: {cohen_kappa_score(y_train, y_train_pred_class)}')\n",
    "    print(f\"Eval Accuracy: {accuracy_score(y_true, y_eval_pred_class):.4f}\")\n",
    "    print(f'Eval Kappa: {cohen_kappa_score(y_true, y_eval_pred_class)}')\n",
    "\n",
    "    print(\"\\nClassification Report:\")\n",
    "    print(classification_report(y_true, y_eval_pred_class))\n",
    "    \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.11.14)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
